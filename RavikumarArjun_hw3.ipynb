{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Specifying Tasks performed\n",
    "Delete any tasks you were *unable* to perform:\n",
    "1. Successfully ran notebook as is; accuracy = 0.664\n",
    "2. Successfully ran notebook with 1300 training samples; accuracy = 0.764\n",
    "3. Successfully ran notebook with a new set of pretrained features; accuracy = 0.812\n",
    "4. Successfully ran notebook with a different classifier; accuracy = 0.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Loading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\"01beach\":0, \"02forest\":1, \"03mountain\":2,\n",
    "          \"04city\":3, \"05suburb\":4, \"06street\":5,\n",
    "          \"07bedroom\":6, \"08kitchen\":7, \"09livingroom\":8,\n",
    "          \"10store\":9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add this since openCV open function was removed\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will load the training and testing csv files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_csv(os.path.relpath('./train250.csv'))\n",
    "train_a[\"label\"] = train_a[\"label\"].map(labels)\n",
    "Xtrain, Ytrain = [], []\n",
    "for index, row in train_a.iterrows():\n",
    "  img = pil_loader(os.path.realpath('./'+row['filepath']))\n",
    "  Xtrain.append(np.array(img))\n",
    "  Ytrain.append(row['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = pd.read_csv(os.path.relpath('./test250.csv'))\n",
    "test_a[\"label\"] = test_a[\"label\"].map(labels)\n",
    "Xtest, Ytest= [], []\n",
    "for index, row in test_a.iterrows():\n",
    "  img = pil_loader(os.path.realpath('./'+row['filepath']))\n",
    "  Xtest.append(np.array(img))\n",
    "  Ytest.append(row['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train is 250 and length of test is 250\n"
     ]
    }
   ],
   "source": [
    "train_len = len(train_a)\n",
    "test_len = len(test_a)\n",
    "print(f'length of train is {train_len} and length of test is {test_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the input to 224x224x3 since this is the required shape for VGG-16\n",
    "\n",
    "We will also normalize the train and test images with mean --> (0.485, 0.456, 0.406) and standard deviation --> (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Xtrain)):\n",
    "  Xtrain[i] = transform.resize(Xtrain[i], (224, 224))\n",
    "  Xtrain[i] = (Xtrain[i] - (0.485, 0.456, 0.406)) / (0.229, 0.224, 0.225)\n",
    "    \n",
    "Xtrain = np.array(Xtrain)\n",
    "Xtrain = torch.from_numpy(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Xtest)):\n",
    "  Xtest[i] = transform.resize(Xtest[i], (224, 224))\n",
    "  Xtest[i] = (Xtest[i] - (0.485, 0.456, 0.406)) / (0.229, 0.224, 0.225)\n",
    "    \n",
    "Xtest = np.array(Xtest)\n",
    "Xtest = torch.from_numpy(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data in the following format --> (number of images, channels, height, width) as this is the expected input shape for the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.permute(0, 3, 1, 2).float()\n",
    "Xtest =   Xtest.permute(0, 3, 1, 2).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature Extraction using Pre-trained CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use VGG-16 for extracting features from the images. For BONUS, you can try other pretrained networks like DenseNet.\n",
    "\n",
    "For extracting features from the pretrained models we can use any layer. The choice of which layer we want to use can be experimented with. Here I have removed the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and use the pretrained VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This portion takes a long time to run on a CPU\n",
    "vgg = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "modules=list(vgg.children())[:-1]\n",
    "vgg=nn.Sequential(*modules)\n",
    "vgg = vgg.to(device)\n",
    "vgg.eval()\n",
    "x_vgg_train = []\n",
    "\n",
    "# The training set has 1300 images, which many GPUs cannot handle in a single batch, so we will pass the data\n",
    "# in batches of 250 images\n",
    "for i in range(0, len(Xtrain), 250):\n",
    "  x_vgg_train.append(vgg(Xtrain[i:i+250].to(device)).cpu().numpy())\n",
    "\n",
    "X_vgg_train = np.vstack(x_vgg_train)\n",
    "X_vgg_train_np = X_vgg_train.reshape(train_len, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Training and Predicting with the Classifier\n",
    "\n",
    "We will train a RandomForest classifier using the pretrained CNN features we obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the classifier and fit to the training data and labels\n",
    "rf_vgg = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "rf_vgg.fit(X_vgg_train_np, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now apply the trained classifier to the test data\n",
    "X_vgg_test = vgg(Xtest.to(device)).cpu().numpy()\n",
    "X_vgg_test_np = X_vgg_test.reshape(test_len, -1)\n",
    "Y_vgg_rf_predictions = rf_vgg.predict(X_vgg_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Obtaining Performance Metrics\n",
    "\n",
    "Metrics using the VGG-16 as the feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Random Forest model using VGG-16 feature extractor is 0.664\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18,  1,  5,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0, 25,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  1, 22,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1, 12,  1,  7,  0,  0,  1,  3],\n",
       "       [ 0,  3,  0,  0, 19,  2,  0,  0,  0,  1],\n",
       "       [ 1,  0,  0,  1,  3, 19,  0,  0,  0,  1],\n",
       "       [ 1,  0,  0,  1,  1,  0, 14,  4,  3,  1],\n",
       "       [ 0,  0,  0,  3,  1,  0,  1, 12,  5,  3],\n",
       "       [ 0,  0,  0,  1,  0,  1,  4,  5, 13,  1],\n",
       "       [ 0,  0,  1,  2,  1,  0,  2,  3,  4, 12]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The accuracy for the Random Forest model using VGG-16 feature extractor is {}\".format(accuracy_score(Ytest, Y_vgg_rf_predictions)))\n",
    "print()\n",
    "confusion_matrix(Ytest, Y_vgg_rf_predictions, labels=[0,1,2,3,4,5,6,7,8,9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Retraining using 1300 data set\n",
    "\n",
    "Using VGG-16 as the feature extractor and Random forest with 1300 data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_csv(os.path.relpath('./train1300.csv'))\n",
    "train_a[\"label\"] = train_a[\"label\"].map(labels)\n",
    "Xtrain, Ytrain = [], []\n",
    "for index, row in train_a.iterrows():\n",
    "  img = pil_loader(os.path.realpath('./'+row['filepath']))\n",
    "  Xtrain.append(np.array(img))\n",
    "  Ytrain.append(row['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train is 1300 and length of test is 250\n"
     ]
    }
   ],
   "source": [
    "train_len = len(train_a)\n",
    "test_len = len(test_a)\n",
    "print(f'length of train is {train_len} and length of test is {test_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Xtrain)):\n",
    "  Xtrain[i] = transform.resize(Xtrain[i], (224, 224))\n",
    "  Xtrain[i] = (Xtrain[i] - (0.485, 0.456, 0.406)) / (0.229, 0.224, 0.225)\n",
    "    \n",
    "Xtrain = np.array(Xtrain)\n",
    "Xtrain = torch.from_numpy(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.permute(0, 3, 1, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This portion takes a long time to run on a CPU\n",
    "vgg = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "modules=list(vgg.children())[:-1]\n",
    "vgg=nn.Sequential(*modules)\n",
    "vgg = vgg.to(device)\n",
    "vgg.eval()\n",
    "x_vgg_train = []\n",
    "\n",
    "# The training set has 1300 images, which many GPUs cannot handle in a single batch, so we will pass the data\n",
    "# in batches of 250 images\n",
    "for i in range(0, len(Xtrain), 250):\n",
    "  x_vgg_train.append(vgg(Xtrain[i:i+250].to(device)).cpu().numpy())\n",
    "\n",
    "X_vgg_train = np.vstack(x_vgg_train)\n",
    "X_vgg_train_np = X_vgg_train.reshape(train_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the classifier and fit to the training data and labels\n",
    "rf_vgg = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "rf_vgg.fit(X_vgg_train_np, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now apply the trained classifier to the test data\n",
    "X_vgg_test = vgg(Xtest.to(device)).cpu().numpy()\n",
    "X_vgg_test_np = X_vgg_test.reshape(test_len, -1)\n",
    "Y_vgg_rf_predictions = rf_vgg.predict(X_vgg_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Random Forest model using VGG-16 feature extractor is 0.764\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22,  0,  1,  0,  1,  0,  1,  0,  0,  0],\n",
       "       [ 0, 24,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0, 22,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 21,  1,  2,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 25,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  1,  1, 20,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  1,  0,  0, 13,  6,  5,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1,  2, 16,  3,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  5, 13,  3],\n",
       "       [ 0,  1,  0,  1,  0,  2,  2,  1,  3, 15]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The accuracy for the Random Forest model using VGG-16 feature extractor is {}\".format(accuracy_score(Ytest, Y_vgg_rf_predictions)))\n",
    "print()\n",
    "confusion_matrix(Ytest, Y_vgg_rf_predictions, labels=[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Training using Densenet and Random Forest\n",
    "\n",
    "Using Densenet161 and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet161 = models.densenet161(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in densenet161.parameters():\n",
    "    param.requires_grad = False\n",
    "modules=list(densenet161.children())[:-1]\n",
    "densenet161=nn.Sequential(*modules)\n",
    "densenet161 = densenet161.to(device)\n",
    "densenet161.eval()\n",
    "x_densenet161_train = []\n",
    "\n",
    "# The training set has 1300 images, which many GPUs cannot handle in a single batch, so we will pass the data\n",
    "# in batches of 250 images\n",
    "for i in range(0, len(Xtrain), 250):\n",
    "  x_densenet161_train.append(densenet161(Xtrain[i:i+250].to(device)).cpu().numpy())\n",
    "\n",
    "X_densenet161_train = np.vstack(x_densenet161_train)\n",
    "X_densenet161_train_np = X_densenet161_train.reshape(train_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the classifier and fit to the training data and labels\n",
    "rf_densenet161 = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "rf_densenet161.fit(X_densenet161_train_np, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now apply the trained classifier to the test data\n",
    "X_densenet161_test = densenet161(Xtest.to(device)).cpu().numpy()\n",
    "X_densenet161_test_np = X_densenet161_test.reshape(test_len, -1)\n",
    "Y_densenet161_rf_predictions = rf_densenet161.predict(X_densenet161_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Random Forest model using DenseNet161 feature extractor is 0.812\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, 20,  3,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  2, 23,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 21,  2,  1,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  2, 23,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  3,  0, 21,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 18,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2, 17,  5,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  6,  4, 15,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  4,  0, 20]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The accuracy for the Random Forest model using DenseNet161 feature extractor is {}\".format(accuracy_score(Ytest, Y_densenet161_rf_predictions)))\n",
    "print()\n",
    "confusion_matrix(Ytest, Y_densenet161_rf_predictions, labels=[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Training using Densenet and Extra Trees Classifier\n",
    "\n",
    "Using Densenet161 and Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=0, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the classifier and fit to the training data and labels\n",
    "et_densenet161 = ExtraTreesClassifier(max_depth=10, random_state=0)\n",
    "et_densenet161.fit(X_densenet161_train_np, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now apply the trained classifier to the test data\n",
    "X_densenet161_test = densenet161(Xtest.to(device)).cpu().numpy()\n",
    "X_densenet161_test_np = X_densenet161_test.reshape(test_len, -1)\n",
    "Y_densenet161_et_predictions = et_densenet161.predict(X_densenet161_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Decision Tree model using DenseNet161 feature extractor is 0.8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[24,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 23,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1, 22,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 18,  4,  3,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 23,  2,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  3,  1, 20,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 16,  4,  5,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1, 18,  5,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  3, 17,  3],\n",
       "       [ 0,  0,  0,  1,  0,  2,  0,  1,  2, 19]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The accuracy for the Extra Trees Classifier using DenseNet161 feature extractor is {}\".format(accuracy_score(Ytest, Y_densenet161_et_predictions)))\n",
    "print()\n",
    "confusion_matrix(Ytest, Y_densenet161_et_predictions, labels=[0,1,2,3,4,5,6,7,8,9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
